{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOWYca4Q9lf3",
        "outputId": "6040fd20-76ca-4779-a00c-1921651400ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from pandas import DataFrame\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=\"Artificial intelligence has rapidly transformed many industries by enabling machines to learn from data and perform tasks that traditionally required human intelligence. Advances in natural language processing allow computers to understand and generate human language, making interactions with technology more intuitive and effective. With the growth of big data and improved computational power, deep learning models have become central to breakthroughs in image recognition, speech processing, and autonomous systems. As these technologies evolve, ethical considerations and responsible AI development are increasingly important to ensure beneficial outcomes for society.\"\n"
      ],
      "metadata": {
        "id": "UR-5PbIVGBhY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "7iJq_TugGXpb",
        "outputId": "5c27b7e6-8322-4cff-e3e0-1178c85b1591"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Artificial intelligence has rapidly transformed many industries by enabling machines to learn from data and perform tasks that traditionally required human intelligence. Advances in natural language processing allow computers to understand and generate human language, making interactions with technology more intuitive and effective. With the growth of big data and improved computational power, deep learning models have become central to breakthroughs in image recognition, speech processing, and autonomous systems. As these technologies evolve, ethical considerations and responsible AI development are increasingly important to ensure beneficial outcomes for society.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REMOVING SPECIAL CHARACTERS"
      ],
      "metadata": {
        "id": "o6QNE3BpHMV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in '!@#$~%^&*()_+-=[]{}\\|;:\",/<>?\"\\n':\n",
        "  corpus=corpus.replace(i,' ')\n"
      ],
      "metadata": {
        "id": "D32J9gIYGjYP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "vsssvRu_H3Sw",
        "outputId": "cc87d216-2f48-4c97-a889-e0bd93d5b0a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Artificial intelligence has rapidly transformed many industries by enabling machines to learn from data and perform tasks that traditionally required human intelligence. Advances in natural language processing allow computers to understand and generate human language  making interactions with technology more intuitive and effective. With the growth of big data and improved computational power  deep learning models have become central to breakthroughs in image recognition  speech processing  and autonomous systems. As these technologies evolve  ethical considerations and responsible AI development are increasingly important to ensure beneficial outcomes for society.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words=word_tokenize(corpus)\n",
        "\n",
        "vocab=list(set([word for word in words if len(word)!=0]))\n",
        "word_index={word:i for i,word in enumerate(vocab)}\n",
        "index_word={word_index[word]:word for word in word_index}"
      ],
      "metadata": {
        "id": "wi8IRmUvH5tL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDKG3w31Iys0",
        "outputId": "ba26f9af-fc03-45c1-e5af-3099b5e705e7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'required': 0,\n",
              " 'computational': 1,\n",
              " 'improved': 2,\n",
              " 'computers': 3,\n",
              " '.': 4,\n",
              " 'traditionally': 5,\n",
              " 'natural': 6,\n",
              " 'generate': 7,\n",
              " 'with': 8,\n",
              " 'learning': 9,\n",
              " 'autonomous': 10,\n",
              " 'ethical': 11,\n",
              " 'increasingly': 12,\n",
              " 'society': 13,\n",
              " 'the': 14,\n",
              " 'learn': 15,\n",
              " 'language': 16,\n",
              " 'become': 17,\n",
              " 'AI': 18,\n",
              " 'in': 19,\n",
              " 'models': 20,\n",
              " 'tasks': 21,\n",
              " 'growth': 22,\n",
              " 'central': 23,\n",
              " 'are': 24,\n",
              " 'data': 25,\n",
              " 'processing': 26,\n",
              " 'Advances': 27,\n",
              " 'evolve': 28,\n",
              " 'beneficial': 29,\n",
              " 'ensure': 30,\n",
              " 'effective': 31,\n",
              " 'many': 32,\n",
              " 'that': 33,\n",
              " 'intuitive': 34,\n",
              " 'systems': 35,\n",
              " 'more': 36,\n",
              " 'intelligence': 37,\n",
              " 'transformed': 38,\n",
              " 'by': 39,\n",
              " 'for': 40,\n",
              " 'breakthroughs': 41,\n",
              " 'and': 42,\n",
              " 'responsible': 43,\n",
              " 'these': 44,\n",
              " 'understand': 45,\n",
              " 'rapidly': 46,\n",
              " 'industries': 47,\n",
              " 'considerations': 48,\n",
              " 'important': 49,\n",
              " 'has': 50,\n",
              " 'As': 51,\n",
              " 'deep': 52,\n",
              " 'machines': 53,\n",
              " 'allow': 54,\n",
              " 'interactions': 55,\n",
              " 'With': 56,\n",
              " 'to': 57,\n",
              " 'technology': 58,\n",
              " 'power': 59,\n",
              " 'big': 60,\n",
              " 'enabling': 61,\n",
              " 'of': 62,\n",
              " 'speech': 63,\n",
              " 'image': 64,\n",
              " 'have': 65,\n",
              " 'perform': 66,\n",
              " 'development': 67,\n",
              " 'Artificial': 68,\n",
              " 'technologies': 69,\n",
              " 'recognition': 70,\n",
              " 'outcomes': 71,\n",
              " 'from': 72,\n",
              " 'human': 73,\n",
              " 'making': 74}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sqlq20IkJHUo",
        "outputId": "20109024-5292-4daf-eb7d-a73b9159bd27"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'required',\n",
              " 1: 'computational',\n",
              " 2: 'improved',\n",
              " 3: 'computers',\n",
              " 4: '.',\n",
              " 5: 'traditionally',\n",
              " 6: 'natural',\n",
              " 7: 'generate',\n",
              " 8: 'with',\n",
              " 9: 'learning',\n",
              " 10: 'autonomous',\n",
              " 11: 'ethical',\n",
              " 12: 'increasingly',\n",
              " 13: 'society',\n",
              " 14: 'the',\n",
              " 15: 'learn',\n",
              " 16: 'language',\n",
              " 17: 'become',\n",
              " 18: 'AI',\n",
              " 19: 'in',\n",
              " 20: 'models',\n",
              " 21: 'tasks',\n",
              " 22: 'growth',\n",
              " 23: 'central',\n",
              " 24: 'are',\n",
              " 25: 'data',\n",
              " 26: 'processing',\n",
              " 27: 'Advances',\n",
              " 28: 'evolve',\n",
              " 29: 'beneficial',\n",
              " 30: 'ensure',\n",
              " 31: 'effective',\n",
              " 32: 'many',\n",
              " 33: 'that',\n",
              " 34: 'intuitive',\n",
              " 35: 'systems',\n",
              " 36: 'more',\n",
              " 37: 'intelligence',\n",
              " 38: 'transformed',\n",
              " 39: 'by',\n",
              " 40: 'for',\n",
              " 41: 'breakthroughs',\n",
              " 42: 'and',\n",
              " 43: 'responsible',\n",
              " 44: 'these',\n",
              " 45: 'understand',\n",
              " 46: 'rapidly',\n",
              " 47: 'industries',\n",
              " 48: 'considerations',\n",
              " 49: 'important',\n",
              " 50: 'has',\n",
              " 51: 'As',\n",
              " 52: 'deep',\n",
              " 53: 'machines',\n",
              " 54: 'allow',\n",
              " 55: 'interactions',\n",
              " 56: 'With',\n",
              " 57: 'to',\n",
              " 58: 'technology',\n",
              " 59: 'power',\n",
              " 60: 'big',\n",
              " 61: 'enabling',\n",
              " 62: 'of',\n",
              " 63: 'speech',\n",
              " 64: 'image',\n",
              " 65: 'have',\n",
              " 66: 'perform',\n",
              " 67: 'development',\n",
              " 68: 'Artificial',\n",
              " 69: 'technologies',\n",
              " 70: 'recognition',\n",
              " 71: 'outcomes',\n",
              " 72: 'from',\n",
              " 73: 'human',\n",
              " 74: 'making'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sents=[word_tokenize(sent) for sent in sent_tokenize(corpus)]\n",
        "sents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OOntET2JPGX",
        "outputId": "f0100392-3182-4078-e6a6-f428f1cb845b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Artificial',\n",
              "  'intelligence',\n",
              "  'has',\n",
              "  'rapidly',\n",
              "  'transformed',\n",
              "  'many',\n",
              "  'industries',\n",
              "  'by',\n",
              "  'enabling',\n",
              "  'machines',\n",
              "  'to',\n",
              "  'learn',\n",
              "  'from',\n",
              "  'data',\n",
              "  'and',\n",
              "  'perform',\n",
              "  'tasks',\n",
              "  'that',\n",
              "  'traditionally',\n",
              "  'required',\n",
              "  'human',\n",
              "  'intelligence',\n",
              "  '.'],\n",
              " ['Advances',\n",
              "  'in',\n",
              "  'natural',\n",
              "  'language',\n",
              "  'processing',\n",
              "  'allow',\n",
              "  'computers',\n",
              "  'to',\n",
              "  'understand',\n",
              "  'and',\n",
              "  'generate',\n",
              "  'human',\n",
              "  'language',\n",
              "  'making',\n",
              "  'interactions',\n",
              "  'with',\n",
              "  'technology',\n",
              "  'more',\n",
              "  'intuitive',\n",
              "  'and',\n",
              "  'effective',\n",
              "  '.'],\n",
              " ['With',\n",
              "  'the',\n",
              "  'growth',\n",
              "  'of',\n",
              "  'big',\n",
              "  'data',\n",
              "  'and',\n",
              "  'improved',\n",
              "  'computational',\n",
              "  'power',\n",
              "  'deep',\n",
              "  'learning',\n",
              "  'models',\n",
              "  'have',\n",
              "  'become',\n",
              "  'central',\n",
              "  'to',\n",
              "  'breakthroughs',\n",
              "  'in',\n",
              "  'image',\n",
              "  'recognition',\n",
              "  'speech',\n",
              "  'processing',\n",
              "  'and',\n",
              "  'autonomous',\n",
              "  'systems',\n",
              "  '.'],\n",
              " ['As',\n",
              "  'these',\n",
              "  'technologies',\n",
              "  'evolve',\n",
              "  'ethical',\n",
              "  'considerations',\n",
              "  'and',\n",
              "  'responsible',\n",
              "  'AI',\n",
              "  'development',\n",
              "  'are',\n",
              "  'increasingly',\n",
              "  'important',\n",
              "  'to',\n",
              "  'ensure',\n",
              "  'beneficial',\n",
              "  'outcomes',\n",
              "  'for',\n",
              "  'society',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING DATA"
      ],
      "metadata": {
        "id": "uA93ELyeJmNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_data(window_size):\n",
        "  features=[]\n",
        "  labels=[]\n",
        "  for sent in sents:\n",
        "    for i in range(len(sent)-window_size*2):\n",
        "      features.append(sent[i:i+window_size]+sent[i+window_size+1:i+window_size*2+1])\n",
        "      labels.append(sent[i+window_size])\n",
        "  return features,labels"
      ],
      "metadata": {
        "id": "QLWpiIHxJncY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features,labels=train_data(1)"
      ],
      "metadata": {
        "id": "Y0NxLF7jPyKE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaUrnEgQQMM_",
        "outputId": "b1660a54-1dda-49a4-91cd-86dbb759c3ee"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Artificial', 'has'], ['intelligence', 'rapidly'], ['has', 'transformed'], ['rapidly', 'many'], ['transformed', 'industries'], ['many', 'by'], ['industries', 'enabling'], ['by', 'machines'], ['enabling', 'to'], ['machines', 'learn'], ['to', 'from'], ['learn', 'data'], ['from', 'and'], ['data', 'perform'], ['and', 'tasks'], ['perform', 'that'], ['tasks', 'traditionally'], ['that', 'required'], ['traditionally', 'human'], ['required', 'intelligence'], ['human', '.'], ['Advances', 'natural'], ['in', 'language'], ['natural', 'processing'], ['language', 'allow'], ['processing', 'computers'], ['allow', 'to'], ['computers', 'understand'], ['to', 'and'], ['understand', 'generate'], ['and', 'human'], ['generate', 'language'], ['human', 'making'], ['language', 'interactions'], ['making', 'with'], ['interactions', 'technology'], ['with', 'more'], ['technology', 'intuitive'], ['more', 'and'], ['intuitive', 'effective'], ['and', '.'], ['With', 'growth'], ['the', 'of'], ['growth', 'big'], ['of', 'data'], ['big', 'and'], ['data', 'improved'], ['and', 'computational'], ['improved', 'power'], ['computational', 'deep'], ['power', 'learning'], ['deep', 'models'], ['learning', 'have'], ['models', 'become'], ['have', 'central'], ['become', 'to'], ['central', 'breakthroughs'], ['to', 'in'], ['breakthroughs', 'image'], ['in', 'recognition'], ['image', 'speech'], ['recognition', 'processing'], ['speech', 'and'], ['processing', 'autonomous'], ['and', 'systems'], ['autonomous', '.'], ['As', 'technologies'], ['these', 'evolve'], ['technologies', 'ethical'], ['evolve', 'considerations'], ['ethical', 'and'], ['considerations', 'responsible'], ['and', 'AI'], ['responsible', 'development'], ['AI', 'are'], ['development', 'increasingly'], ['are', 'important'], ['increasingly', 'to'], ['important', 'ensure'], ['to', 'beneficial'], ['ensure', 'outcomes'], ['beneficial', 'for'], ['outcomes', 'society'], ['for', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0O5yW3nQN3Q",
        "outputId": "3ee7be91-ef77-4bdf-eaca-291669114f44"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['intelligence', 'has', 'rapidly', 'transformed', 'many', 'industries', 'by', 'enabling', 'machines', 'to', 'learn', 'from', 'data', 'and', 'perform', 'tasks', 'that', 'traditionally', 'required', 'human', 'intelligence', 'in', 'natural', 'language', 'processing', 'allow', 'computers', 'to', 'understand', 'and', 'generate', 'human', 'language', 'making', 'interactions', 'with', 'technology', 'more', 'intuitive', 'and', 'effective', 'the', 'growth', 'of', 'big', 'data', 'and', 'improved', 'computational', 'power', 'deep', 'learning', 'models', 'have', 'become', 'central', 'to', 'breakthroughs', 'in', 'image', 'recognition', 'speech', 'processing', 'and', 'autonomous', 'systems', 'these', 'technologies', 'evolve', 'ethical', 'considerations', 'and', 'responsible', 'AI', 'development', 'are', 'increasingly', 'important', 'to', 'ensure', 'beneficial', 'outcomes', 'for', 'society']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode():\n",
        "  x_train=[]\n",
        "  y_train=[]\n",
        "  for feature in features:\n",
        "    enc=np.zeros(len(word_index))\n",
        "    for word in feature:\n",
        "      enc[word_index[word]]=1\n",
        "    x_train.append(enc)\n",
        "  for label in labels:\n",
        "    enc=np.zeros(len(word_index))\n",
        "    enc[word_index[label]]=1\n",
        "    y_train.append(enc)\n",
        "  return np.array(x_train),np.array(y_train)"
      ],
      "metadata": {
        "id": "QP5ZRskQRiWx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=encode()"
      ],
      "metadata": {
        "id": "ydBdxnfVSDq7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2FCE6uMPwwD",
        "outputId": "dcfaf53d-9363-4665-8517-752b2e3e9b76"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84, 75)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sl5Qy4SSk9q",
        "outputId": "319df278-a047-4d49-ec6e-4270b87ffe5f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84, 75)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BUILDING THE NEURAL NETWORK"
      ],
      "metadata": {
        "id": "fCy2X-jASUiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Input layer to hidden layer with 100 neurons, input_dim = vocab size\n",
        "model.add(Dense(100, input_dim=len(word_index), activation='relu'))\n",
        "\n",
        "# Output layer with softmax over vocab size (predict probability distribution over words)\n",
        "model.add(Dense(len(word_index), activation='softmax'))\n",
        "\n",
        "# Compile with categorical crossentropy (multi-class classification) and Adam optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train on your data\n",
        "model.fit(x, y, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Get predictions (probabilities over vocab for each input sample)\n",
        "predictions = model.predict(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uIfMYa4SYnX",
        "outputId": "e5b9f08f-78a7-4634-855c-4208546f045a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0099 - loss: 4.3437     \n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0394 - loss: 4.3112\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0316 - loss: 4.2853    \n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0670 - loss: 4.2501\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0729 - loss: 4.2274\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1417 - loss: 4.1980\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1538 - loss: 4.1849\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1949 - loss: 4.1559\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2266 - loss: 4.1286\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3560 - loss: 4.0867\n",
            "Epoch 11/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3718 - loss: 4.0547\n",
            "Epoch 12/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3231 - loss: 4.0446\n",
            "Epoch 13/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4271 - loss: 4.0035\n",
            "Epoch 14/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4509 - loss: 3.9838\n",
            "Epoch 15/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4764 - loss: 3.9512\n",
            "Epoch 16/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5156 - loss: 3.9213\n",
            "Epoch 17/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5218 - loss: 3.8811 \n",
            "Epoch 18/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5433 - loss: 3.8507\n",
            "Epoch 19/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5435 - loss: 3.8205\n",
            "Epoch 20/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5592 - loss: 3.7835\n",
            "Epoch 21/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5592 - loss: 3.7454\n",
            "Epoch 22/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5766 - loss: 3.7031\n",
            "Epoch 23/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5924 - loss: 3.6555\n",
            "Epoch 24/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5398 - loss: 3.6389\n",
            "Epoch 25/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6317 - loss: 3.5770\n",
            "Epoch 26/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6103 - loss: 3.5335\n",
            "Epoch 27/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5986 - loss: 3.5040\n",
            "Epoch 28/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6280 - loss: 3.4374\n",
            "Epoch 29/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6163 - loss: 3.3982\n",
            "Epoch 30/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6376 - loss: 3.3459\n",
            "Epoch 31/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6397 - loss: 3.3051\n",
            "Epoch 32/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6516 - loss: 3.2475\n",
            "Epoch 33/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6693 - loss: 3.1906 \n",
            "Epoch 34/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6987 - loss: 3.1367\n",
            "Epoch 35/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7184 - loss: 3.0826 \n",
            "Epoch 36/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6577 - loss: 3.0726 \n",
            "Epoch 37/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7163 - loss: 2.9842 \n",
            "Epoch 38/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6890 - loss: 2.9199 \n",
            "Epoch 39/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6968 - loss: 2.8551\n",
            "Epoch 40/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6715 - loss: 2.8205 \n",
            "Epoch 41/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7184 - loss: 2.7523 \n",
            "Epoch 42/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7087 - loss: 2.6923 \n",
            "Epoch 43/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7381 - loss: 2.6318\n",
            "Epoch 44/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7305 - loss: 2.5984 \n",
            "Epoch 45/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7578 - loss: 2.5098\n",
            "Epoch 46/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7383 - loss: 2.4402 \n",
            "Epoch 47/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8010 - loss: 2.3826\n",
            "Epoch 48/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7796 - loss: 2.3424\n",
            "Epoch 49/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8266 - loss: 2.2859\n",
            "Epoch 50/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8268 - loss: 2.2126\n",
            "Epoch 51/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8484 - loss: 2.1635 \n",
            "Epoch 52/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8622 - loss: 2.1210\n",
            "Epoch 53/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8584 - loss: 2.0838\n",
            "Epoch 54/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8858 - loss: 1.9287\n",
            "Epoch 55/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9035 - loss: 1.8857\n",
            "Epoch 56/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9289 - loss: 1.8233\n",
            "Epoch 57/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9310 - loss: 1.7891\n",
            "Epoch 58/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9018 - loss: 1.7567\n",
            "Epoch 59/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9663 - loss: 1.6460\n",
            "Epoch 60/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9567 - loss: 1.6298\n",
            "Epoch 61/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9626 - loss: 1.5760\n",
            "Epoch 62/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9764 - loss: 1.5121\n",
            "Epoch 63/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9803 - loss: 1.4293\n",
            "Epoch 64/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9725 - loss: 1.4127\n",
            "Epoch 65/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9725 - loss: 1.3429\n",
            "Epoch 66/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9823 - loss: 1.3122\n",
            "Epoch 67/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9901 - loss: 1.2876\n",
            "Epoch 68/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 1.1806\n",
            "Epoch 69/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9940 - loss: 1.1219\n",
            "Epoch 70/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9901 - loss: 1.0646\n",
            "Epoch 71/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9823 - loss: 1.0869\n",
            "Epoch 72/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9823 - loss: 1.0240\n",
            "Epoch 73/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9901 - loss: 0.9720\n",
            "Epoch 74/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9940 - loss: 0.9345\n",
            "Epoch 75/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9940 - loss: 0.8873\n",
            "Epoch 76/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9901 - loss: 0.8375\n",
            "Epoch 77/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.7949\n",
            "Epoch 78/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.7633\n",
            "Epoch 79/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.7305\n",
            "Epoch 80/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.7063\n",
            "Epoch 81/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.6842\n",
            "Epoch 82/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.6554\n",
            "Epoch 83/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.6196\n",
            "Epoch 84/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.6133\n",
            "Epoch 85/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.5510\n",
            "Epoch 86/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.5596\n",
            "Epoch 87/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.5384\n",
            "Epoch 88/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.5161\n",
            "Epoch 89/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.4883\n",
            "Epoch 90/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.4701\n",
            "Epoch 91/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.4451\n",
            "Epoch 92/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.4342\n",
            "Epoch 93/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.4147\n",
            "Epoch 94/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.4152\n",
            "Epoch 95/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.3930\n",
            "Epoch 96/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.3630\n",
            "Epoch 97/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.3677\n",
            "Epoch 98/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.3474\n",
            "Epoch 99/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.3346\n",
            "Epoch 100/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.3229\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIMILAR WORDS"
      ],
      "metadata": {
        "id": "qzTltWKtTvqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_embedding=model.get_weights()[0]"
      ],
      "metadata": {
        "id": "9il5NRzyTxB8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def similar_words(word,top_n):\n",
        "  if word not in word_index:\n",
        "    print('Word not in corpus')\n",
        "    return\n",
        "  idx=word_index[word]\n",
        "  emb=word_embedding[idx]\n",
        "\n",
        "  distances = np.dot(word_embedding, emb)\n",
        "\n",
        "  distance_idx=distances.argsort()[::-1]\n",
        "  distance_idx=[idx for idx in distance_idx if index_word[idx]!=word][:top_n]\n",
        "  return [(index_word[idx],distances[idx]) for idx in distance_idx]"
      ],
      "metadata": {
        "id": "PTYFZXHXI2LI"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_words=similar_words('technology',10)"
      ],
      "metadata": {
        "id": "OX9PAaBKbPjq"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMLe47Fnb6VS",
        "outputId": "3c7187e1-388f-47cc-fe7a-802f6fde1363"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('intuitive', np.float32(1.0595355)),\n",
              " ('learn', np.float32(0.7786558)),\n",
              " ('become', np.float32(0.74701947)),\n",
              " ('interactions', np.float32(0.707564)),\n",
              " ('tasks', np.float32(0.67822164)),\n",
              " ('enabling', np.float32(0.6655196)),\n",
              " ('from', np.float32(0.58182836)),\n",
              " ('for', np.float32(0.5707735)),\n",
              " ('computational', np.float32(0.50692534)),\n",
              " ('image', np.float32(0.42680812))]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}